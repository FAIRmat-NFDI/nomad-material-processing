#
# Copyright The NOMAD Authors.
#
# This file is part of NOMAD. See https://nomad-lab.eu for further info.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from datetime import datetime
from typing import TYPE_CHECKING

import numpy as np
import pandas as pd
import plotly.graph_objects as go

from nomad.config import config
from nomad.datamodel.data import ArchiveSection, EntryData, Schema
from nomad.datamodel.metainfo.annotations import ELNAnnotation
from nomad.datamodel.metainfo.basesections import (
    Activity,
    CompositeSystem,
    Experiment,
    ExperimentStep,
    Process,
    ProcessStep,
    PublicationReference,
)
from nomad.datamodel.metainfo.plot import PlotlyFigure, PlotSection
from nomad.metainfo import (
    Datetime,
    SchemaPackage,
    Section,
    SubSection,
    Quantity,
)

from nomad_material_processing.solution.general import (
    Solution,
    SolutionReference,
)

if TYPE_CHECKING:
    from nomad.datamodel.datamodel import EntryArchive
    from structlog.stdlib import BoundLogger

m_package = SchemaPackage(
    name='Precipitation  Schema')

configuration = config.get_plugin_entry_point(
    'nomad_material_processing.sample_solidification:precipitation_schema',
)




class AddingSolution(ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    reference = Quantity(
        type=Solution,
        description=' ',
        a_eln={'component': 'ReferenceEditQuantity', 'label': 'Solution'},
    )
    amount_of_solution = Quantity(
        type=np.float64,
        description=' ',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': 'milliliter'},
        shape=[1],
        unit='milliliter',
    )
    rate = Quantity(
        type=np.float64,
        description=' ',
        a_eln={
            'component': 'NumberEditQuantity',
            'defaultDisplayUnit': 'milliliter/minute',
        },
        shape=[1],
        unit='milliliter/minute',
    )


class ReactorProgramStep(ProcessStep, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    elapsed_time = Quantity(
        type=np.float64,
        description='elapsed time since start of the experiment',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': 'second'},
        # shape=[1],
        unit='second',
    )
    start_time = Quantity(
        type=Datetime,
        description='end time of the process step',
        a_eln={'component': 'DateTimeEditQuantity'},
        # shape=[1],
    )
    end_time = Quantity(
        type=Datetime,
        description='end time of the process step',
        a_eln={'component': 'DateTimeEditQuantity'},
        # shape=[1],
    )
    stirring_ration_speed = Quantity(
        type=np.float64,
        description=' ',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': '1/minute'},
        # shape=[1],
        unit='1/minute',
    )
    temperature_setpoint = Quantity(
        type=np.float64,
        description=' ',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': '\u00b0C'},
        # shape=[1],
        unit='\u00b0C',
    )
    heating_rate = Quantity(
        type=np.float64,
        description=' ',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': 'K/minute'},
        # shape=[1],
        unit='K/minute',
    )
    AddingSolution = SubSection(
        section_def=AddingSolution,
        base_sections=['CompositeSystemReference'],
        repeats=True,
    )

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `ReactorProgramStep` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


class ReactorDataLog(ArchiveSection):
    m_def = Section()
    local_time = Quantity(
        type=Datetime,
        shape=['*'],
        description='date and time of the log entry',
        # a_eln={'component': 'DateTimeEditQuantity'},
    )
    elapsed_time = Quantity(
        type=np.float64,
        unit='second',
        shape=['*'],
        description='elapsed time since start of the experiment',
        a_display={'unit': 'second'},
    )
    total_volume = Quantity(
        type=np.float64,
        shape=['*'],
        description='total volume of Ca(NO3)2 Ce(NO3)3 in the reactor',
        unit='milliliter',
        a_eln=ELNAnnotation(defaultDisplayUnit='milliliter'),
    )
    conductivity = Quantity(
        type=np.float64,
        shape=['*'],
        description='conductivity of the solution in the reactor',
        unit='milliseconds/centimeter',
    )
    ph = Quantity(
        type=np.float64,
        shape=['*'],
        description='pH value of the solution in the reactor',
    )
    temperature = Quantity(
        type=np.float64,
        shape=['*'],
        description='temperature of the solution in the reactor',
        unit='\u00b0C',
        a_eln=ELNAnnotation(defaultDisplayUnit='celsius'),
    )
    # next quantities are from Mettler Toledo Optimax 1001, add more if needed
    dosing1_mass_a = Quantity(
        type=np.float64,
        shape=['*'],
        description='mass of dosing 1 component A',
        unit='gram',
        a_display={'unit': 'gram'},
    )
    dosing2_mass_b = Quantity(
        type=np.float64,
        shape=['*'],
        description='mass of dosing 2 component B',
        unit='gram',
        a_eln=ELNAnnotation(defaultDisplayUnit='gram'),
    )
    temperature_j = Quantity(
        type=np.float64,
        shape=['*'],
        description='temperature of the heatcarrier surrounding the reactor (jacket)',
        unit='\u00b0C',
        a_eln=ELNAnnotation(defaultDisplayUnit='celsius'),
    )


class ReactorProgram(Process, PlotSection, Schema, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    data_file = Quantity(
        type=str,
        description="""
        A reference to an uploaded .csv from the synthesis process.
        """,
        a_browser={'adaptor': 'RawFileAdaptor'},
        a_eln={'component': 'FileEditQuantity'},
    )
    reactordatalog = SubSection(
        section_def=ReactorDataLog,
        a_eln=None,
    )
    steps = SubSection(
        section_def=ProcessStep,
        repeats=True,
    )

    def read_csv(self, file_path):
        # Read the CSV file (assuming 'file_path' is the path to your CSV file)
        # Strings to match in the CSV header
        strings_to_match = [
            'Local Time (Timezone: UTC2:00)',
            'Experiment Time',
            'Ca(NO3)2 Ce(NO3)3.TotalVolume',
            'Leitfähigkeit',
            'pH-Druck',
            'Tr',
        ]

        # New column names
        new_column_names = [
            'local_time',
            'elapsed_time',
            'total_volume',
            'conductivity',
            'ph',
            'temperature',
        ]

        # Mapping of strings to match to new column names
        column_mapping = dict(zip(strings_to_match, new_column_names))
        # file_path = 'csv_data/MRO016 Reactor data 2016-09-28 CaP ohne IR.csv'

        df = pd.read_csv(
            file_path,
            header=0,
            sep=';',
            decimal=',',
            skiprows=[1],
        )

        # Identify and select matching columns, then rename them
        df_renamed = df.rename(
            columns={
                col: column_mapping[col] for col in df.columns if col in column_mapping
            }
        )

        # Ensure 'local_time' is parsed as datetime if not already done
        df_renamed['local_time'] = pd.to_datetime(df_renamed['local_time'])
        df_renamed['elapsed_time'] = df_renamed['elapsed_time'].apply(
            lambda x: (
                datetime.strptime(x, '%H:%M:%S')
                - datetime.strptime('00:00:00', '%H:%M:%S')
            ).total_seconds()
        )
        # Print the DataFrame to verify
        # print(df_renamed.head())
        return df_renamed

    # read_csv(file_path)
    def read_csv_methrom(self, file_path):
        # Read the CSV file (assuming 'file_path' is the path to your CSV file)
        # Strings to match in the CSV header
        strings_to_match = [
            'Time [s]',
            'Measured value',
            'dU/dt [mV/min]',
            'Temperature [ｰC]',
        ]

        # New column names
        new_column_names = [
            'elapsed_time',
            'total_volume',
            'conductivity',
            'temperature',
        ]

        # Mapping of strings to match to new column names
        column_mapping = dict(zip(strings_to_match, new_column_names))

        df = pd.read_csv(
            file_path,
            header=3,
            sep=';',
            # decimal=',',
            # skiprows=[1],
        )

        # Identify and select matching columns, then rename them
        df_renamed = df.rename(
            columns={
                col: column_mapping[col] for col in df.columns if col in column_mapping
            }
        )

        return df_renamed

    def read_excel_optimax1001(self, file_path):
        optimax_cols = [
            'Abs. Time (UTC+02 : 00)',
            'Rel. Time (in s)',
            'Dosing1.MassA',
            'Dosing2.MassB',
            'pH1',
            'Tj',
            'Tr',
            'Vr',
        ]
        new_column_names = [
            'local_time',
            'elapsed_time',
            'dosing1_mass_a',
            'dosing2_mass_b',
            'ph',
            'temperature_j',
            'temperature',
            'total_volume',
            #'conductivity',
        ]
        column_mapping = dict(zip(optimax_cols, new_column_names))
        df = pd.read_excel(file_path, skiprows=[1])  # usecols=optimax_cols,
        df.fillna(method='ffill', inplace=True)
        df = df.rename(
            columns={
                col: column_mapping[col] for col in df.columns if col in column_mapping
            }
        )
        return df

    def read_steps_excel_optimax1001(self, file_path):
        """Read the steps from the excel file"""
        optimax_recipe_cols = [
            '#',
            'Type',
            'Action / Note / Sample',
            'Duration',
            'Start Time',
            'End Time',
            'Tr',
            'Tj',
            'R',
            'Mr',
            'Vr',
        ]
        new_column_names = [
            'number',
            'type',
            'step name',
            'duration',
            'elapsed_time',
            'end_time_elapsed',
            'temperature',
            'temperature_j',
            'stirring_rotation_speed',
            'added_mass',
            'total_volume',
        ]
        column_mapping = dict(zip(optimax_recipe_cols, new_column_names))
        df = pd.read_excel(file_path, sheet_name='Recipe')
        df = df.rename(
            columns={
                col: column_mapping[col] for col in df.columns if col in column_mapping
            }
        )
        return df

    def add_steps_from_excel(self, df):
        """Add the steps from the excel file to the ReactorProgram"""
        import datetime
        import time

        steps = []
        for index, row in df.iterrows():
            step = ReactorProgramStep()
            step.name = row['step name']
            if pd.isnull(row['duration']) is False:
                print(row['duration'])
                x = time.strptime(row['duration'], '%H:%M:%S')
                step.duration = datetime.timedelta(
                    hours=x.tm_hour, minutes=x.tm_min, seconds=x.tm_sec
                ).total_seconds()
            step.comment = row['type'] + ':\n ' + row['step name']
            y = time.strptime(row['elapsed_time'], '%H:%M:%S')
            step.elapsed_time = datetime.timedelta(
                hours=y.tm_hour, minutes=y.tm_min, seconds=y.tm_sec
            ).total_seconds()
            step.stirring_ration_speed = float(
                row['stirring_rotation_speed'].split(' ')[0]
            )  # unit is 1/min
            step.temperature_setpoint = float(
                row['temperature'].split(' ')[0]
            )  # unit is celcius
            steps.append(step)
        self.steps = steps

    def check_strings_in_first_row(self, archive, file_path):
        """
        Checks if specified strings are in the first row of each CSV file in the
        directory.
        """

        # Strings to check in the CSV header
        strings_to_check = [
            'Local Time (Timezone: UTC2:00)',
            'Experiment Time',
            'Ca(NO3)2 Ce(NO3)3.TotalVolume',
            'Leitfähigkeit',
            'pH-Druck',
            'Tr',
        ]
        strings_to_check_methrom = [
            'Time [s]',
            'Measured value',
            'dU/dt [mV/min]',
            'Temperature [ｰC]',
        ]

        if file_path.endswith('.csv'):
            with archive.m_context.raw_file(file_path) as f:
                first_line = f.readline().strip()
                for _ in range(3):
                    next(f)
                # Read the fourth line
                fourth_line = f.readline()
                # Check if any of the specified strings are in the first line
                found_strings = [s for s in strings_to_check if s in first_line]
                found_methrom_strings = [
                    s for s in strings_to_check_methrom if s in fourth_line
                ]

                if found_strings:
                    # print(f"Found in {file}: {', '.join(found_strings)}")
                    df = self.read_csv(f.name)
                    return df
                elif found_methrom_strings:
                    # print(f"Found in {file}: {', '.join(found_strings)}")
                    df = self.read_csv_methrom(f.name)
                    return df
                else:
                    print(f'No specified strings found in the first row of {f.name}')
        elif file_path.endswith('.xlsx'):
            with archive.m_context.raw_file(file_path) as f:
                df = self.read_excel_optimax1001(f.name)
                df2 = self.read_steps_excel_optimax1001(f.name)
                self.add_steps_from_excel(df2)
                return df

    def plot_multiple_y_axes_colored(self, df, df_steps):
        # Initialize the figure
        fig = go.Figure()

        # Colors for each line/axis
        colors = ['blue', 'green', 'red', 'purple', 'orange', 'brown', 'pink']

        # Check and add traces for each column with corresponding axis settings
        if 'elapsed_time' in df.columns:
            if 'total_volume' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['total_volume'],
                        name='Total Volume',
                        marker_color=colors[0],
                    )
                )
                fig.update_layout(
                    xaxis_title='Elapsed Time / s',
                    xaxis=dict(domain=[0.1, 0.8]),
                    yaxis=dict(
                        title='Volume / mL',
                        titlefont=dict(color=colors[0]),
                        tickfont=dict(color=colors[0]),
                        shift=50,
                    ),
                )

            if 'conductivity' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['conductivity'],
                        name='Conductivity',
                        marker_color=colors[1],
                        yaxis='y2',
                    )
                )
                fig.update_layout(
                    yaxis2=dict(
                        title='Conductivity / mS/cm',
                        titlefont=dict(color=colors[1]),
                        tickfont=dict(color=colors[1]),
                        tickmode='sync',
                        overlaying='y',
                        anchor='x',
                        side='right',
                        position=1,
                    )
                )

            if 'ph' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['ph'],
                        name='pH',
                        marker_color=colors[2],
                        yaxis='y3',
                    )
                )
                fig.update_layout(
                    yaxis3=dict(
                        title='pH',
                        titlefont=dict(color=colors[2]),
                        tickfont=dict(color=colors[2]),
                        tickmode='sync',
                        overlaying='y',
                        side='right',
                        anchor='free',
                        autoshift=True,
                        position=0.8,
                        shift=150,
                        title_standoff=0,
                    )
                )

            if 'temperature' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['temperature'],
                        name='Temperature',
                        marker_color=colors[3],
                        yaxis='y4',
                    )
                )
                fig.update_layout(
                    yaxis4=dict(
                        title='Temperature / °C',
                        titlefont=dict(color=colors[3]),
                        tickfont=dict(color=colors[3]),
                        overlaying='y',
                        tickmode='sync',
                        side='right',
                        anchor='free',
                        position=0.9,
                        title_standoff=0,
                    )
                )
            if 'dosing1_mass_a' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['dosing1_mass_a'],
                        name='Dosing 1 Mass A',
                        marker_color=colors[4],
                        yaxis='y5',
                    )
                )
                fig.update_layout(
                    yaxis5=dict(
                        title='Mass Dosing Solutions / g',
                        titlefont=dict(color=colors[4]),
                        tickfont=dict(color=colors[4]),
                        tickmode='sync',
                        overlaying='y',
                        anchor='free',
                        autoshift=True,
                        shift=-150,
                    )
                )
            if 'dosing2_mass_b' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['dosing2_mass_b'],
                        name='Dosing 2 Mass B',
                        marker_color=colors[5],
                        yaxis='y5',
                    )
                )
                # fig.update_layout(
                #     yaxis6=dict(
                #         title='Dosing 2 Mass B / g',
                #         titlefont=dict(color=colors[5]),
                #         tickfont=dict(color=colors[5]),
                #         overlaying='y',
                #         side='right',
                #         anchor='free',
                #         position=0.8,
                #     )
                # )
            if 'temperature_j' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['temperature_j'],
                        name='Temperature Jacket',
                        marker_color=colors[6],
                        yaxis='y4',
                    )
                )
                # fig.update_layout(
                #     yaxis7=dict(
                #         title='Temperature J / °C',
                #         titlefont=dict(color=colors[6]),
                #         tickfont=dict(color=colors[6]),
                #         overlaying='y',
                #         side='right',
                #         anchor='free',
                #         position=0.7,
                #     )
                # )

        # Update layout to adjust the right margin to accommodate the extra y-axes
        fig.update_layout(showlegend=True)  # , margin=dict(pad=20))  # r=200))
        if df_steps.empty is False:
            if not df_steps['elapsed_time'].empty:
                for index, row in df_steps.iterrows():
                    fig.add_vline(
                        x=row['elapsed_time'],
                        line_dash='dash',
                        line_color='gray',
                        # annotation_text=row['name'],
                        # annotation_position='top right',
                    )
        return fig

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `ReactorProgram` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)
        if self.data_file is not None:
            df_datalog = self.check_strings_in_first_row(archive, self.data_file)
            reactordatalog = ReactorDataLog()
            columns = df_datalog.columns
            if 'local_time' in columns:
                reactordatalog.local_time = df_datalog['local_time'].tolist()
            if 'elapsed_time' in columns:
                reactordatalog.elapsed_time = df_datalog['elapsed_time'].tolist()
            if 'total_volume' in columns:
                reactordatalog.total_volume = df_datalog['total_volume'].tolist()
            if 'conductivity' in columns:
                reactordatalog.conductivity = df_datalog['conductivity'].tolist()
            if 'ph' in columns:
                reactordatalog.ph = df_datalog['ph'].tolist()
            if 'temperature' in columns:
                reactordatalog.temperature = df_datalog['temperature'].tolist()
            if 'dosing1_mass_a' in columns:
                reactordatalog.dosing1_mass_a = df_datalog['dosing1_mass_a'].tolist()
            if 'dosing2_mass_b' in columns:
                reactordatalog.dosing2_mass_b = df_datalog['dosing2_mass_b'].tolist()
            if 'temperature_j' in columns:
                reactordatalog.temperature_j = df_datalog['temperature_j'].tolist()

            self.reactordatalog = reactordatalog

            if self.steps:
                df_steps = pd.DataFrame(
                    columns=['stepnumber', 'name', 'duration', 'elapsed_time']
                )
                counter = 0
                for step in self.steps:
                    counter += 1
                    if isinstance(step, ReactorProgramStep):
                        if step.duration is not None:
                            df_steps = df_steps.append(
                                {
                                    'stepnumber': counter,
                                    'name': step.name,
                                    'duration': step.duration.to('s').magnitude,
                                    'elapsed_time': step.elapsed_time.to('s').magnitude,
                                },
                                ignore_index=True,
                            )
                df_steps['duration'] = df_steps['duration'].astype(float)
                df_steps['elapsed_time'] = df_steps['elapsed_time'].astype(float)
            else:
                df_steps = None
            figure1 = self.plot_multiple_y_axes_colored(df_datalog, df_steps)
            self.figures = []
            self.figures.append(
                PlotlyFigure(label='figure 1', figure=figure1.to_plotly_json())
            )


class CaP_Experiment(Experiment, Schema, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    Based_on_Experiment = Quantity(
        type=str,  # CaP_Experiment,
        description='the experiment this experiment is based on',
        a_eln={'component': 'StringEditQuantity'},  # 'ReferenceEditQuantity'},
    )
    Difference_to_previous_experiment = Quantity(
        type=str,
        description='differences to previous experiment',
        a_eln={'component': 'StringEditQuantity'},
        shape=['*'],
    )
    Based_on_publication = SubSection(
        section_def=PublicationReference,
        a_eln=None,
    )
    steps = SubSection(
        section_def=ExperimentStep,
        repeats=True,
    )
    solutions = SubSection(
        section_def=SolutionReference,
        repeats=True,
    )

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `CaP_Experiment` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


# the classes below will be implemented soon:
# class Excitation(ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     Wavelenght = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )
#     Slit = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )


# class Emission(ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     Detector = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "StringEditQuantity"
#         },
#     )
#     Integration_time = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "second"
#         },
#         shape=[1],
#         unit="second",
#     )
#     DetectorSlit = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )
#     GratingLines = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity"
#         },
#         shape=[1],
#     )
#     GratingCenter = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )
#     UnknownSetting = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "StringEditQuantity"
#         },
#     )
#     Cycles = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity"
#         },
#         shape=[1],
#     )
#     Delay = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "second"
#         },
#         shape=[1],
#         unit="second",
#     )
#     Dark_offset = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "StringEditQuantity"
#         },
#     )


# class MeasurementSettings(ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     excitation = SubSection(
#         section_def=Excitation,
#     )
#     emission = SubSection(
#         section_def=Emission,
#     )


# class LuminescenceMeasurements(Measurement, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     Filter = Quantity(
#         type=np.float64,
#         description='optical filter',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )
#     Measurement_Option = Quantity(
#         type=MEnum(['in-situ', 'ex-situ']),
#         description='Measurement option',
#         a_eln={
#             "component": "RadioEnumEditQuantity"
#         },
#     )
#     measurement_settings = SubSection(
#         section_def=MeasurementSettings,
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `LuminescenceMeasurements` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class Sensors(Process, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     List_of_sensors = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "StringEditQuantity"
#         },
#     )
#     Sensor_setup_drawing = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "RichTextEditQuantity"
#         },
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `Sensors` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class SampleRemoval(Process, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     Sample_removal = Quantity(
#         type=bool,
#         a_eln={
#             "component": "BoolEditQuantity"
#         },
#     )
#     steps = SubSection(
#         section_def=SampleRemovalSteps,
#         repeats=True,
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `SampleRemoval` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class SampleRemovalSteps(ProcessStep, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     sample_at_removal_time = Quantity(
#         type=CaP_sample,
#         description='sample that was removed from the reactor at a given time in minutes',
#         a_eln={
#             "component": "ReferenceEditQuantity"
#         },
#     )
#     duration = Quantity(
#         type=np.float64,
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "minute",
#             "label": "removal time in minutes"
#         },
#         unit="minute",
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `SampleRemovalSteps` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class SampleTreatment(Process, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     steps = SubSection(
#         section_def=SampleTreatmentSteps,
#         repeats=True,
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `SampleTreatment` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class SampleTreatmentSteps(ProcessStep, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `SampleTreatmentSteps` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class Rest(SampleTreatmentSteps, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `Rest` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class PrepareForXRD(SampleTreatmentSteps, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `PrepareForXRD` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class Results(Analysis, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `Results` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


m_package.__init_metainfo__()
