#
# Copyright The NOMAD Authors.
#
# This file is part of NOMAD. See https://nomad-lab.eu for further info.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

from datetime import datetime
from typing import TYPE_CHECKING

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.graph_objs as go
from nomad.datamodel.data import ArchiveSection, EntryData
from nomad.datamodel.metainfo.basesections import (
    Activity,
    CompositeSystem,
    Experiment,
    ExperimentStep,
    Process,
    ProcessStep,
    PublicationReference,
)
from nomad.datamodel.metainfo.plot import PlotlyFigure, PlotSection
from nomad.metainfo import Datetime, Package, Quantity, Section, SubSection

if TYPE_CHECKING:
    from nomad.datamodel.datamodel import EntryArchive
    from structlog.stdlib import BoundLogger

m_package = Package(name='Crystallization')


class Solution(CompositeSystem, EntryData, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `Solution` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


class Solutions(ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    precursor = Quantity(
        type=Solution,
        a_eln={'component': 'ReferenceEditQuantity'},
    )


class CaPActivity(Activity, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `CaPActivity` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


class CaPSteps(ExperimentStep, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    activity = Quantity(
        type=CaPActivity,
        a_eln={'component': 'ReferenceEditQuantity'},
    )

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `CaPSteps` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


class CaP_sample(CompositeSystem, EntryData, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `CaP_sample` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


class SolutionPreparation(Process, CaPActivity, EntryData, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `SolutionPreparation` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


class ProgramSteps(ProcessStep, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `ProgramSteps` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


class AddingSolution(ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    reference = Quantity(
        type=Solution,
        description=' ',
        a_eln={'component': 'ReferenceEditQuantity', 'label': 'Solution'},
    )
    amount_of_solution = Quantity(
        type=np.float64,
        description=' ',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': 'milliliter'},
        shape=[1],
        unit='milliliter',
    )
    rate = Quantity(
        type=np.float64,
        description=' ',
        a_eln={
            'component': 'NumberEditQuantity',
            'defaultDisplayUnit': 'milliliter/minute',
        },
        shape=[1],
        unit='milliliter/minute',
    )


class ReactorProgramStep(ProgramSteps, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    elapsed_time = Quantity(
        type=np.float64,
        description='elapsed time since start of the experiment',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': 'second'},
        # shape=[1],
        unit='second',
    )
    start_time = Quantity(
        type=Datetime,
        description='end time of the process step',
        a_eln={'component': 'DateTimeEditQuantity'},
        # shape=[1],
    )
    end_time = Quantity(
        type=Datetime,
        description='end time of the process step',
        a_eln={'component': 'DateTimeEditQuantity'},
        # shape=[1],
    )
    stirring_ration_speed = Quantity(
        type=np.float64,
        description=' ',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': '1/minute'},
        # shape=[1],
        unit='1/minute',
    )
    temperature_setpoint = Quantity(
        type=np.float64,
        description=' ',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': '\u00b0C'},
        # shape=[1],
        unit='\u00b0C',
    )
    heating_rate = Quantity(
        type=np.float64,
        description=' ',
        a_eln={'component': 'NumberEditQuantity', 'defaultDisplayUnit': 'K/minute'},
        # shape=[1],
        unit='K/minute',
    )
    AddingSolution = SubSection(
        section_def=AddingSolution,
        base_sections=['CompositeSystemReference'],
        repeats=True,
    )

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `ReactorProgramStep` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


class ReactorDataLog(ArchiveSection):
    m_def = Section()
    local_time = Quantity(
        type=Datetime,
        shape=['*'],
        description='date and time of the log entry',
        # a_eln={'component': 'DateTimeEditQuantity'},
    )
    elapsed_time = Quantity(
        type=np.float64,
        unit='second',
        shape=['*'],
        description='elapsed time since start of the experiment',
    )
    total_volume = Quantity(
        type=np.float64,
        shape=['*'],
        description='total volume of Ca(NO3)2 Ce(NO3)3 in the reactor',
        unit='milliliter',
    )
    conductivity = Quantity(
        type=np.float64,
        shape=['*'],
        description='conductivity of the solution in the reactor',
        unit='milliseconds/centimeter',
    )
    ph = Quantity(
        type=np.float64,
        shape=['*'],
        description='pH value of the solution in the reactor',
    )
    temperature = Quantity(
        type=np.float64,
        shape=['*'],
        description='temperature of the solution in the reactor',
        unit='\u00b0C',
    )
    # next quantities are from Mettler Toledo Optimax 1001, add more if needed
    dosing1_mass_a = Quantity(
        type=np.float64,
        shape=['*'],
        description='mass of dosing 1 component A',
        unit='gram',
    )
    dosing2_mass_b = Quantity(
        type=np.float64,
        shape=['*'],
        description='mass of dosing 2 component B',
        unit='gram',
    )
    temperature_j = Quantity(
        type=np.float64,
        shape=['*'],
        description='temperature of the j?',
        unit='\u00b0C',
    )


class ReactorProgram(Process, CaPActivity, PlotSection, EntryData, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    data_file = Quantity(
        type=str,
        description="""
        A reference to an uploaded .csv from the synthesis process.
        """,
        a_browser={'adaptor': 'RawFileAdaptor'},
        a_eln={'component': 'FileEditQuantity'},
    )
    reactordatalog = SubSection(
        section_def=ReactorDataLog,
        a_eln=None,
    )
    steps = SubSection(
        section_def=ProgramSteps,
        repeats=True,
    )

    def read_csv(self, file_path):
        # Read the CSV file (assuming 'file_path' is the path to your CSV file)
        # Strings to match in the CSV header
        strings_to_match = [
            'Local Time (Timezone: UTC2:00)',
            'Experiment Time',
            'Ca(NO3)2 Ce(NO3)3.TotalVolume',
            'Leitfähigkeit',
            'pH-Druck',
            'Tr',
        ]

        # New column names
        new_column_names = [
            'local_time',
            'elapsed_time',
            'total_volume',
            'conductivity',
            'ph',
            'temperature',
        ]

        # Mapping of strings to match to new column names
        column_mapping = dict(zip(strings_to_match, new_column_names))
        # file_path = 'csv_data/MRO016 Reactor data 2016-09-28 CaP ohne IR.csv'

        df = pd.read_csv(
            file_path,
            header=0,
            sep=';',
            decimal=',',
            skiprows=[1],
        )

        # Identify and select matching columns, then rename them
        df_renamed = df.rename(
            columns={
                col: column_mapping[col] for col in df.columns if col in column_mapping
            }
        )

        # Ensure 'local_time' is parsed as datetime if not already done
        df_renamed['local_time'] = pd.to_datetime(df_renamed['local_time'])
        df_renamed['elapsed_time'] = df_renamed['elapsed_time'].apply(
            lambda x: (
                datetime.strptime(x, '%H:%M:%S')
                - datetime.strptime('00:00:00', '%H:%M:%S')
            ).total_seconds()
        )
        # Print the DataFrame to verify
        # print(df_renamed.head())
        return df_renamed

    # read_csv(file_path)
    def read_csv_methrom(self, file_path):
        # Read the CSV file (assuming 'file_path' is the path to your CSV file)
        # Strings to match in the CSV header
        strings_to_match = [
            'Time [s]',
            'Measured value',
            'dU/dt [mV/min]',
            'Temperature [ｰC]',
        ]

        # New column names
        new_column_names = [
            'elapsed_time',
            'total_volume',
            'conductivity',
            'temperature',
        ]

        # Mapping of strings to match to new column names
        column_mapping = dict(zip(strings_to_match, new_column_names))

        # file_path = 'csv_data/MRO016 Reactor data 2016-09-28 CaP ohne IR.csv'

        df = pd.read_csv(
            file_path,
            header=3,
            sep=';',
            # decimal=',',
            # skiprows=[1],
        )

        # Identify and select matching columns, then rename them
        df_renamed = df.rename(
            columns={
                col: column_mapping[col] for col in df.columns if col in column_mapping
            }
        )

        return df_renamed

    def read_excel_optimax1001(self, file_path):
        optimax_cols = [
            'Abs. Time (UTC+02 : 00)',
            'Rel. Time (in s)',
            'Dosing1.MassA',
            'Dosing2.MassB',
            'pH1',
            'Tj',
            'Tr',
            'Vr',
        ]
        new_column_names = [
            'local_time',
            'elapsed_time',
            'dosing1_mass_a',
            'dosing2_mass_b',
            'ph',
            'temperature_j',
            'temperature',
            'total_volume',
            #'conductivity',
        ]
        column_mapping = dict(zip(optimax_cols, new_column_names))
        df = pd.read_excel(file_path, usecols=optimax_cols, skiprows=[1])
        df.fillna(method='ffill', inplace=True)
        df = df.rename(
            columns={
                col: column_mapping[col] for col in df.columns if col in column_mapping
            }
        )
        return df

    def check_strings_in_first_row(self, archive, file_path):
        """Checks if specified strings are in the first row of each CSV file in the directory."""
        # Find all CSV files in the directory
        # csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]

        # Strings to check in the CSV header
        strings_to_check = [
            'Local Time (Timezone: UTC2:00)',
            'Experiment Time',
            'Ca(NO3)2 Ce(NO3)3.TotalVolume',
            'Leitfähigkeit',
            'pH-Druck',
            'Tr',
        ]
        strings_to_check_methrom = [
            'Time [s]',
            'Measured value',
            'dU/dt [mV/min]',
            'Temperature [ｰC]',
        ]
        # Iterate over the list of CSV files
        # for file in csv_files:
        #     # Construct full file path
        #     file_path = os.path.join(directory_path, file)
        # Open the file and read the first line
        # with open(file_path) as f:
        if file_path.endswith('.csv'):
            with archive.m_context.raw_file(file_path) as f:
                first_line = f.readline().strip()
                for _ in range(3):
                    next(f)
                # Read the fourth line
                fourth_line = f.readline()
                # Check if any of the specified strings are in the first line
                found_strings = [s for s in strings_to_check if s in first_line]
                found_methrom_strings = [
                    s for s in strings_to_check_methrom if s in fourth_line
                ]
                # Print the results
                if found_strings:
                    # print(f"Found in {file}: {', '.join(found_strings)}")
                    df = self.read_csv(f.name)
                    return df
                elif found_methrom_strings:
                    # print(f"Found in {file}: {', '.join(found_strings)}")
                    df = self.read_csv_methrom(f.name)
                    return df
                else:
                    print(f'No specified strings found in the first row of {f.name}')
        elif file_path.endswith('.xlsx'):
            with archive.m_context.raw_file(file_path) as f:
                df = self.read_excel_optimax1001(f.name)
                return df

    def plot_multiple_y_axes_colored(self, df, df_steps):
        # Initialize the figure
        fig = go.Figure()

        # Colors for each line/axis
        colors = ['blue', 'green', 'red', 'purple', 'orange', 'brown', 'pink']

        # Check and add traces for each column with corresponding axis settings
        if 'elapsed_time' in df.columns:
            if 'total_volume' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['total_volume'],
                        name='Total Volume',
                        marker_color=colors[0],
                    )
                )
                fig.update_layout(
                    xaxis_title='Elapsed Time',
                    yaxis=dict(
                        title='Total Volume / mL',
                        titlefont=dict(color=colors[0]),
                        tickfont=dict(color=colors[0]),
                    ),
                )

            if 'conductivity' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['conductivity'],
                        name='Conductivity',
                        marker_color=colors[1],
                        yaxis='y2',
                    )
                )
                fig.update_layout(
                    yaxis2=dict(
                        title='Conductivity / mS/cm',
                        titlefont=dict(color=colors[1]),
                        tickfont=dict(color=colors[1]),
                        overlaying='y',
                        side='right',
                    )
                )

            if 'ph' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['ph'],
                        name='pH',
                        marker_color=colors[2],
                        yaxis='y3',
                    )
                )
                fig.update_layout(
                    yaxis3=dict(
                        title='pH',
                        titlefont=dict(color=colors[2]),
                        tickfont=dict(color=colors[2]),
                        overlaying='y',
                        side='left',
                        anchor='free',
                        position=0.1,
                    )
                )

            if 'temperature' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['temperature'],
                        name='Temperature',
                        marker_color=colors[3],
                        yaxis='y4',
                    )
                )
                fig.update_layout(
                    yaxis4=dict(
                        title='Temperature / °C',
                        titlefont=dict(color=colors[3]),
                        tickfont=dict(color=colors[3]),
                        overlaying='y',
                        side='right',
                        anchor='free',
                        position=0.9,
                    )
                )
            if 'dosing1_mass_a' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['dosing1_mass_a'],
                        name='Dosing 1 Mass A',
                        marker_color=colors[4],
                        yaxis='y5',
                    )
                )
                fig.update_layout(
                    yaxis5=dict(
                        title='Dosing 1 Mass A / g',
                        titlefont=dict(color=colors[4]),
                        tickfont=dict(color=colors[4]),
                        overlaying='y',
                        side='left',
                        anchor='free',
                        position=0.2,
                    )
                )
            if 'dosing2_mass_b' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['dosing2_mass_b'],
                        name='Dosing 2 Mass B',
                        marker_color=colors[5],
                        yaxis='y6',
                    )
                )
                fig.update_layout(
                    yaxis6=dict(
                        title='Dosing 2 Mass B / g',
                        titlefont=dict(color=colors[5]),
                        tickfont=dict(color=colors[5]),
                        overlaying='y',
                        side='right',
                        anchor='free',
                        position=0.8,
                    )
                )
            if 'temperature_j' in df.columns:
                fig.add_trace(
                    go.Scatter(
                        x=df['elapsed_time'],
                        y=df['temperature_j'],
                        name='Temperature J',
                        marker_color=colors[6],
                        yaxis='y7',
                    )
                )
                fig.update_layout(
                    yaxis7=dict(
                        title='Temperature J / °C',
                        titlefont=dict(color=colors[6]),
                        tickfont=dict(color=colors[6]),
                        overlaying='y',
                        side='right',
                        anchor='free',
                        position=0.7,
                    )
                )

        # Update layout to adjust the right margin to accommodate the extra y-axes
        fig.update_layout(margin=dict(r=200))
        if df_steps != None:
            if not df_steps['elapsed_time'].empty:
                for index, row in df_steps.iterrows():
                    fig.add_vline(
                        x=row['elapsed_time'],
                        line_dash='dash',
                        line_color='gray',
                        # annotation_text=row['name'],
                        # annotation_position='top right',
                    )
        return fig

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `ReactorProgram` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)
        if self.data_file is not None:
            # with archive.m_context.raw_file(self.data_file) as file:
            # df_datalog = pd.read_csv(
            #     file,
            #     header=0,
            #     sep=';',
            #     decimal=',',
            #     skiprows=[1],
            #     names=[
            #         'local_time',
            #         'elapsed_time',
            #         'total_volume',
            #         'conductivity',
            #         'ph_pressure',
            #         'temperature',
            #     ],
            #     parse_dates=[
            #         'local_time',
            #     ],
            # )
            # df_datalog['elapsed_time'] = df_datalog['elapsed_time'].apply(
            #     lambda x: (
            #         datetime.strptime(x, '%H:%M:%S')
            #         - datetime.strptime('00:00:00', '%H:%M:%S')
            #     ).total_seconds()
            # )
            # df_datalog['elapsed_time'] = df_datalog['elapsed_time'].astype(float)
            df_datalog = self.check_strings_in_first_row(archive, self.data_file)
            reactordatalog = ReactorDataLog()
            columns = df_datalog.columns
            if 'local_time' in columns:
                reactordatalog.local_time = df_datalog['local_time'].tolist()
            if 'elapsed_time' in columns:
                reactordatalog.elapsed_time = df_datalog['elapsed_time'].tolist()
            if 'total_volume' in columns:
                reactordatalog.total_volume = df_datalog['total_volume'].tolist()
            if 'conductivity' in columns:
                reactordatalog.conductivity = df_datalog['conductivity'].tolist()
            if 'ph' in columns:
                reactordatalog.ph = df_datalog['ph'].tolist()
            if 'temperature' in columns:
                reactordatalog.temperature = df_datalog['temperature'].tolist()
            if 'dosing1_mass_a' in columns:
                reactordatalog.dosing1_mass_a = df_datalog['dosing1_mass_a'].tolist()
            if 'dosing2_mass_b' in columns:
                reactordatalog.dosing2_mass_b = df_datalog['dosing2_mass_b'].tolist()
            if 'temperature_j' in columns:
                reactordatalog.temperature_j = df_datalog['temperature_j'].tolist()

            self.reactordatalog = reactordatalog

            # figure1 = make_subplots(
            #     specs=[[{'secondary_y': True}]]
            # )  # (rows=1, cols=1, shared_yaxes=False)
            # figure1.update_layout(
            #     height=600,
            #     width=900,
            #     title_text='CaP Synthesis Data',
            # )
            # if 'total_volume' in columns:
            #     figure1.add_trace(
            #         go.Scatter(
            #             mode='markers',
            #             x=reactordatalog.elapsed_time,
            #             y=reactordatalog.total_volume,
            #             name='Total Volume',
            #             marker=dict(
            #                 color='blue',
            #                 size=4,
            #             ),
            #         ),
            #         secondary_y=True,
            #         # showlegend=False
            #     )

            #     # first_line = px.scatter(
            #     #     x=reactordatalog.elapsed_time,
            #     #     y=reactordatalog.total_volume,
            #     #     labels={'y': 'Total Volume'},
            #     # )
            #     # figure1.add_trace(first_line, row=1, col=1)
            #     figure1.update_layout(
            #         yaxis=dict(
            #             title='Total Volume',
            #             titlefont=dict(color='blue'),
            #             tickfont=dict(color='blue'),
            #         ),
            #     )
            # if 'temperature' in columns:
            #     figure1.add_trace(
            #         go.Scatter(
            #             mode='markers',
            #             x=reactordatalog.elapsed_time,
            #             y=reactordatalog.temperature,
            #             name='Total Volume',
            #             marker=dict(
            #                 color='red',
            #                 size=4,
            #             ),
            #         ),
            #         secondary_y=True,
            #     )
            #     # showlegend=False

            #     # px.scatter(
            #     #     x=reactordatalog.elapsed_time,
            #     #     y=reactordatalog.temperature,
            #     #     labels={'y': 'Temperature'},
            #     # )
            #     # figure1.add_trace(second_line, row=1, col=1)

            #     figure1.update_layout(
            #         yaxis=dict(
            #             title='Temperature',
            #             titlefont=dict(color='red'),
            #             tickfont=dict(color='red'),
            #             overlaying='y',
            #             side='right',
            #         ),
            #     )

            # if 'conductivity' in columns:
            #     figure1.add_trace(
            #         go.Scatter(
            #             mode='markers',
            #             x=reactordatalog.elapsed_time,
            #             y=reactordatalog.conductivity,
            #             name='Conductivity',
            #             marker=dict(
            #                 color='green',
            #                 size=4,
            #             ),
            #         ),
            #         secondary_y=True,
            #     )
            #     # px.scatter(
            #     #     x=reactordatalog.elapsed_time,
            #     #     y=reactordatalog.conductivity,
            #     #     labels={'y': 'Conductivity'},
            #     # )
            #     # figure1.add_trace(third_line, row=1, col=1)

            #     figure1.update_layout(
            #         yaxis=dict(
            #             title='Conductivity',
            #             titlefont=dict(color='green'),
            #             tickfont=dict(color='green'),
            #             anchor='free',
            #             overlaying='y',
            #             side='left',
            #             position=0.15,
            #         ),
            #     )
            # if 'ph_pressure' in columns:
            #     figure1.add_trace(
            #         go.Scatter(
            #             mode='markers',
            #             x=reactordatalog.elapsed_time,
            #             y=reactordatalog.ph_pressure,
            #             name='pH-Pressure',
            #             marker=dict(
            #                 color='purple',
            #                 size=4,
            #             ),
            #         ),
            #         secondary_y=True,
            #     )
            #     # px.scatter(
            #     #     x=reactordatalog.elapsed_time,
            #     #     y=reactordatalog.ph_pressure,
            #     #     labels={'y': 'pH/Pressure'},

            #     # )
            #     # figure1.add_trace(fourth_line, row=1, col=1)

            #     figure1.update_layout(
            #         yaxis=dict(
            #             title='pH-Pressure',
            #             titlefont=dict(color='purple'),
            #             tickfont=dict(color='purple'),
            #             anchor='free',
            #             overlaying='y',
            #             side='right',
            #             position=0.85,
            #         ),
            #     )
            # figure1.update_layout(
            #     # height=600,
            #     # width=900,
            #     # title_text='CaP Synthesis Data',
            #     # yaxis=dict(
            #     #     title='Total Volume',
            #     #     titlefont=dict(color='blue'),
            #     #     tickfont=dict(color='blue'),
            #     # ),
            #     # yaxis2=dict(
            #     #     title='Temperature',
            #     #     titlefont=dict(color='red'),
            #     #     tickfont=dict(color='red'),
            #     #     overlaying='y',
            #     #     side='right',
            #     # ),
            #     # yaxis3=dict(
            #     #     title='Conductivity',
            #     #     titlefont=dict(color='green'),
            #     #     tickfont=dict(color='green'),
            #     #     anchor='free',
            #     #     overlaying='y',
            #     #     side='left',
            #     #     position=0.15,
            #     # ),
            #     # yaxis4=dict(
            #     #     title='pH/Pressure',
            #     #     titlefont=dict(color='purple'),
            #     #     tickfont=dict(color='purple'),
            #     #     anchor='free',
            #     #     overlaying='y',
            #     #     side='right',
            #     #     position=0.85,
            #     # ),
            #     legend=dict(
            #         x=1,
            #         y=1,
            #         traceorder='normal',
            #         font=dict(family='sans-serif', size=12, color='black'),
            #         bgcolor='LightSteelBlue',
            #         bordercolor='Black',
            #         borderwidth=2,
            #     ),
            # )

            # # Update each trace to correspond to its respective y-axis
            # # figure1.data[0].update(marker=dict(color='blue'))
            # # figure1.data[1].update(yaxis='y2', marker=dict(color='red'))
            # # figure1.data[2].update(yaxis='y3', marker=dict(color='green'))
            # # figure1.data[3].update(yaxis='y4', marker=dict(color='purple'))
            if self.steps:
                df_steps = pd.DataFrame(
                    columns=['stepnumber', 'name', 'duration', 'elapsed_time']
                )
                counter = 0
                for step in self.steps:
                    counter += 1
                    if isinstance(step, ReactorProgramStep):
                        if step.duration is not None:
                            df_steps = df_steps.append(
                                {
                                    'stepnumber': counter,
                                    'name': step.name,
                                    'duration': step.duration.to('s').magnitude,
                                    'elapsed_time': step.elapsed_time.to('s').magnitude,
                                },
                                ignore_index=True,
                            )
                df_steps['duration'] = df_steps['duration'].astype(float)
                df_steps['elapsed_time'] = df_steps['elapsed_time'].astype(float)
            else:
                df_steps = None
            figure1 = self.plot_multiple_y_axes_colored(df_datalog, df_steps)
            self.figures = []
            self.figures.append(
                PlotlyFigure(label='figure 1', figure=figure1.to_plotly_json())
            )


class CaP_Experiment(Experiment, EntryData, ArchiveSection):
    """
    Class autogenerated from yaml schema.
    """

    m_def = Section()
    Based_on_Experiment = Quantity(
        type=str,  # CaP_Experiment,
        description='the experiment this experiment is based on',
        a_eln={'component': 'StringEditQuantity'},  # 'ReferenceEditQuantity'},
    )
    Difference_to_previous_experiment = Quantity(
        type=str,
        description='differences to previous experiment',
        a_eln={'component': 'StringEditQuantity'},
        shape=['*'],
    )
    Based_on_publication = SubSection(
        section_def=PublicationReference,
        a_eln=None,
    )
    steps = SubSection(
        section_def=CaPSteps,
        repeats=True,
    )
    solutions = SubSection(
        section_def=Solutions,
        repeats=True,
    )

    def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
        """
        The normalizer for the `CaP_Experiment` class.

        Args:
            archive (EntryArchive): The archive containing the section that is being
            normalized.
            logger (BoundLogger): A structlog logger.
        """
        super().normalize(archive, logger)


# class Excitation(ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     Wavelenght = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )
#     Slit = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )


# class Emission(ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     Detector = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "StringEditQuantity"
#         },
#     )
#     Integration_time = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "second"
#         },
#         shape=[1],
#         unit="second",
#     )
#     DetectorSlit = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )
#     GratingLines = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity"
#         },
#         shape=[1],
#     )
#     GratingCenter = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )
#     UnknownSetting = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "StringEditQuantity"
#         },
#     )
#     Cycles = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity"
#         },
#         shape=[1],
#     )
#     Delay = Quantity(
#         type=np.float64,
#         description=' ',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "second"
#         },
#         shape=[1],
#         unit="second",
#     )
#     Dark_offset = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "StringEditQuantity"
#         },
#     )


# class MeasurementSettings(ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     excitation = SubSection(
#         section_def=Excitation,
#     )
#     emission = SubSection(
#         section_def=Emission,
#     )


# class LuminescenceMeasurements(Measurement, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     Filter = Quantity(
#         type=np.float64,
#         description='optical filter',
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "nanometer"
#         },
#         shape=[1],
#         unit="nanometer",
#     )
#     Measurement_Option = Quantity(
#         type=MEnum(['in-situ', 'ex-situ']),
#         description='Measurement option',
#         a_eln={
#             "component": "RadioEnumEditQuantity"
#         },
#     )
#     measurement_settings = SubSection(
#         section_def=MeasurementSettings,
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `LuminescenceMeasurements` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class Sensors(Process, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     List_of_sensors = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "StringEditQuantity"
#         },
#     )
#     Sensor_setup_drawing = Quantity(
#         type=str,
#         description=' ',
#         a_eln={
#             "component": "RichTextEditQuantity"
#         },
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `Sensors` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class SampleRemoval(Process, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     Sample_removal = Quantity(
#         type=bool,
#         a_eln={
#             "component": "BoolEditQuantity"
#         },
#     )
#     steps = SubSection(
#         section_def=SampleRemovalSteps,
#         repeats=True,
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `SampleRemoval` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class SampleRemovalSteps(ProcessStep, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     sample_at_removal_time = Quantity(
#         type=CaP_sample,
#         description='sample that was removed from the reactor at a given time in minutes',
#         a_eln={
#             "component": "ReferenceEditQuantity"
#         },
#     )
#     duration = Quantity(
#         type=np.float64,
#         a_eln={
#             "component": "NumberEditQuantity",
#             "defaultDisplayUnit": "minute",
#             "label": "removal time in minutes"
#         },
#         unit="minute",
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `SampleRemovalSteps` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class SampleTreatment(Process, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()
#     steps = SubSection(
#         section_def=SampleTreatmentSteps,
#         repeats=True,
#     )

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `SampleTreatment` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class SampleTreatmentSteps(ProcessStep, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `SampleTreatmentSteps` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class Rest(SampleTreatmentSteps, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `Rest` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class PrepareForXRD(SampleTreatmentSteps, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `PrepareForXRD` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


# class Results(Analysis, CaPActivity, EntryData, ArchiveSection):
#     '''
#     Class autogenerated from yaml schema.
#     '''
#     m_def = Section()

#     def normalize(self, archive: 'EntryArchive', logger: 'BoundLogger') -> None:
#         '''
#         The normalizer for the `Results` class.

#         Args:
#             archive (EntryArchive): The archive containing the section that is being
#             normalized.
#             logger (BoundLogger): A structlog logger.
#         '''
#         super().normalize(archive, logger)


m_package.__init_metainfo__()
